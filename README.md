ğŸ“¡ StreamSync AI â€“ Real-Time Dockerized Chat with LLMs
A fully dockerized, real-time AI chat application that integrates LangGraph-powered AI agents, multiple LLM providers (Groq & OpenAI), and an optional web search tool â€” all wrapped in a Streamlit frontend. Built as part of the Generative AI Internship assignment at 21 Spheres.

ğŸš€ Features
âœ… Supports LLMs from Groq and OpenAI

âœ… Optional real-time web search via Tavily

âœ… Dynamically customizable system prompt

âœ… Interactive UI built with Streamlit

âœ… Asynchronous communication via FastAPI

âœ… Fully containerized with Docker & Docker Compose

ğŸ“ Project Structure
bash
Copy
Edit
StreamSync-AI/
â”‚
â”œâ”€â”€ .venv/                  # Python virtual environment
â”œâ”€â”€ __pycache__/           # Python cache
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env                   # API keys and environment variables
â”œâ”€â”€ docker-compose.yml     # Docker Compose configuration
â”œâ”€â”€ Dockerfile.backend     # Backend Dockerfile
â”œâ”€â”€ Dockerfile.frontend    # Frontend Dockerfile
â”‚
â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚
â”œâ”€â”€ ai_agent.py            # LangGraph AI agent with Tavily tool
â”œâ”€â”€ backend.py             # FastAPI backend for LLM communication
â”œâ”€â”€ frontend.py            # Streamlit UI for chat interaction
ğŸ”§ Setup Instructions
1. Clone the Repository
bash
Copy
Edit
git clone https://github.com/your-username/StreamSync-AI.git
cd StreamSync-AI
2. Setup .env File
Create a .env file in the root directory with the following keys:

env
Copy
Edit
GROQ_API_KEY=your_groq_api_key
OPENAI_API_KEY=your_openai_api_key
TAVILY_API_KEY=your_tavily_api_key
âš ï¸ Ensure valid keys for Groq, OpenAI, and Tavily APIs.

ğŸ³ Docker Deployment
Build & Run Containers
bash
Copy
Edit
docker-compose up --build
The FastAPI backend will run on: http://localhost:9999

The Streamlit frontend will be available at: http://localhost:8501

ğŸ§  Supported LLM Models
Provider	Models
Groq	llama-3.3-70b-versatile, mixtral-8x7b-32768
OpenAI	gpt-4o-mini

ğŸ§ª Example Workflow
Open the Streamlit frontend

Define your system prompt (e.g., â€œAct like a travel assistantâ€)

Select your LLM provider and model

Enable web search if desired

Ask your query!

ğŸ› ï¸ Tech Stack
LangGraph â€“ Agent-based reasoning

LangChain â€“ LLM interfaces

Tavily â€“ External web search

FastAPI â€“ RESTful backend

Streamlit â€“ Frontend UI

Docker â€“ Containerization

